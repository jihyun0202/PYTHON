{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">'탐색적 데이터 분석(EDA)’은 우리가 존재한다고 믿는 것들은 물론이고 존재하지 않는다고 믿는 것들을 발견하려는 태도, 유연성, 그리고 자발성이다.  - 존 튜키 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터에 대한 질문 & 문제 만들기\n",
    "### (2) 데이터를 시각화하고, 변환하고, 모델링하여 그 질문 & 문제에 대한 답을 찾아보기\n",
    "### (3) 찾는 과정에서 배운 것들을 토대로 다시 질문을 다듬고 또 다른 질문 & 문제 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">전체적으로 데이터의 속성들을 살펴본다 - 결측치와 이상치 체크와 대처</span>\n",
    "#### <span style=\"color:red\">속성 간의 관계 분석한다 - 타입, 범주형 연속형 채크, 시각화와 상관계수를 통한 상관성 채크</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA의 핵심 - 데이터의 결측치와 특이값(이상치) 체크와 처리**\n",
    "### 데이터 읽어서 정보 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>265</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>348</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-7</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-3</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1666</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-103</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan contact  \\\n",
       "0   58   management  married   tertiary      no     2143     yes   no     NaN   \n",
       "1   36   technician   single  secondary      no      265     yes  yes     NaN   \n",
       "2   25  blue-collar  married  secondary      no       -7     yes   no     NaN   \n",
       "3   53   technician  married  secondary      no       -3      no   no     NaN   \n",
       "4   24   technician   single  secondary      no     -103     yes  yes     NaN   \n",
       "\n",
       "   day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0    5   may       261         1     -1         0      NaN  no  \n",
       "1    5   may       348         1     -1         0      NaN  no  \n",
       "2    5   may       365         1     -1         0      NaN  no  \n",
       "3    5   may      1666         1     -1         0      NaN  no  \n",
       "4    5   may       145         1     -1         0      NaN  no  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bank_df = pd.read_csv('data/bank.csv')\n",
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7234, 17)\n",
      "age           int64\n",
      "job          object\n",
      "marital      object\n",
      "education    object\n",
      "default      object\n",
      "balance       int64\n",
      "housing      object\n",
      "loan         object\n",
      "contact      object\n",
      "day           int64\n",
      "month        object\n",
      "duration      int64\n",
      "campaign      int64\n",
      "pdays         int64\n",
      "previous      int64\n",
      "poutcome     object\n",
      "y            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 건수, 항목수를 확인\n",
    "print(bank_df.shape)\n",
    "\n",
    "# 데이터형을 확인\n",
    "print(bank_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7234 entries, 0 to 7233\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        7234 non-null   int64 \n",
      " 1   job        7190 non-null   object\n",
      " 2   marital    7234 non-null   object\n",
      " 3   education  6961 non-null   object\n",
      " 4   default    7234 non-null   object\n",
      " 5   balance    7234 non-null   int64 \n",
      " 6   housing    7234 non-null   object\n",
      " 7   loan       7234 non-null   object\n",
      " 8   contact    5196 non-null   object\n",
      " 9   day        7234 non-null   int64 \n",
      " 10  month      7234 non-null   object\n",
      " 11  duration   7234 non-null   int64 \n",
      " 12  campaign   7234 non-null   int64 \n",
      " 13  pdays      7234 non-null   int64 \n",
      " 14  previous   7234 non-null   int64 \n",
      " 15  poutcome   1334 non-null   object\n",
      " 16  y          7234 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 960.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터에 대한 여러가지 정보들을 한번에 출력\n",
    "bank_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술 통계량 확인\n",
    "bank_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = {'menu': ['짜장면', '짬뽕', '탕수육'], 'price' : ['7,000원','8,000원', '10,000원'], 'discountprice' : ['6,000원','7,000원', '8,000원'] }\n",
    "df = pd.DataFrame(food)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['price','discountprice']] = df[['price','discountprice']].apply(lambda x : x.str.replace(',','').str.replace('원','').astype(int)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = {'menu': ['짜장면', '짬뽕', '탕수육'], 'price' : ['7,000원','8,000원', '10,000원'], 'discountprice' : ['6,000원','7,000원', '8,000원'] }\n",
    "df = pd.DataFrame(food)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df.price = df.price.apply(lambda x :re.sub('[,원]','', x)).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.discountprice = df.discountprice.apply(lambda x :re.sub('[,원]','', x)).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(bank_df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno \n",
    "msno.matrix(bank_df, figsize=(12,5), sparkline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바로 위의 셀에서 missingo 오류가 발생하면 다음 셀을 실행시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(bank_df, figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치를 포함한 행 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job과 education 열에서 결측치가 포함된 행을 삭제\n",
    "bank_df = bank_df.dropna(subset=['job', 'education'])\n",
    "\n",
    "# 데이터의 건수, 항목수를 확인\n",
    "print(bank_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치를 2400개이상 포함한 열 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치이 2400개 이상인 열을 제외\n",
    "bank_df = bank_df.dropna(thresh=2400, axis=1) # axis 중요!!!\n",
    "\n",
    "# 데이터의 건수, 항목수를 확인\n",
    "print(bank_df.shape)\n",
    "print(bank_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치을 「unknown」으로 치환\n",
    "bank_df = bank_df.fillna({'contact':'unknown'})\n",
    "\n",
    "# 선두에서 5행까지 표시\n",
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "time_index = pd.date_range(\"2020-01-01\", periods=5, freq=\"MS\")\n",
    "\n",
    "dataframe = pd.DataFrame(index=time_index)\n",
    "\n",
    "dataframe[\"Sales\"] = [1.0,2.0,np.nan,np.nan,5.0]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/fill.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락된 값을 보간합니다.\n",
    "dataframe.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞쪽으로 채우기(Forward-fill)\n",
    "dataframe.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.fillna(method ='ffill') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뒤쪽으로 채우기(Back-fill)\n",
    "dataframe.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.fillna(method ='bfill') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'One' :  [np.nan, np.nan, 95, 80], \n",
    "    'Two' : [np.nan, np.nan, np.nan, np.nan], \n",
    "    'Three':[52, np.nan, 80, 98], \n",
    "    'Four':[np.nan, np.nan, np.nan, 65],\n",
    "    'Five':[10, None, 30, 40],\n",
    "    'Six': [np.nan, np.nan, np.nan, pd.NaT],\n",
    "    'Seven': [np.nan, np.nan, None, np.nan],\n",
    "    'Eight': [np.nan, np.nan, None, pd.NaT]} \n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how = 'all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how = 'all', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['One', 'Four'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Eight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'First Score':[100, 90, None, 95, 85], \n",
    "        'Second Score': [30, 45, None, np.nan, 60], \n",
    "        'Third Score':[np.nan, 40, np.nan, 80, None]} \n",
    "df = pd.DataFrame(dict) \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f2edf591f386>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method ='ffill') #앞에 값으로 채워라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method ='bfill')  #뒤에 값으로 채워라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(to_replace = np.nan, value = -50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate(limit_direction ='forward') #다음값으로 채워주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate(limit_direction ='backward') #이전값으로 채워주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate(limit_direction ='both')  ### ㅎㅎㅎ 이겁니다..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‘맛있는 요리’를 만들기 위해서는 가장 먼저 ‘맛있는 음식재료’를 준비해야 하듯이 데이터 분석에서 맛있는 \n",
    "### 음식재료라고 할 수 있는 EDA가 중요하다는 말이 있다. 원(raw) 데이터를 다양한 방면으로\n",
    "### 관찰하면서 인사이트를 이끌어 낼 수 있다는 것이 EDA의 중요성이다.\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA 작업이후 데이터 전처리에서 필요한 작업 - 범주형 데이터 전처리**\n",
    "### 범주형 변수의 값을 수치로 변환\n",
    "#### 사이킷런은 문자열 값을 입력 값으로 처리 하지 않기 때문에 숫자 형으로 변환해야 함\n",
    "##### 범주형 변수의 경우 전처리를 통해 정수값으로 변환\n",
    "##### 범주형이 아닌 단순 문자열인 경우 일반적으로 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 변수(피쳐)의 처리 방법\n",
    "### - 레이블 인코딩\n",
    "### - 더미화(원 핫 인코딩)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이블 인코딩(Label encoding)\n",
    "#### 문자열(범주형) 값을 0 부터 1씩 증가하는 값으로 변환\n",
    "#### 숫자의 차이가 모델에 영향을 주지 않는 트리 계열 모델(의사결정나무, 랜덤포레스트)에 적용\n",
    "#### 숫자의 차이가 모델에 영향을 미치는 선형 계열 모델(로지스틱회귀, SVM, 신경망)에는 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes를 1、no를 0으로 치환\n",
    "bank_df = bank_df.replace('yes', 1)\n",
    "bank_df = bank_df.replace('no', 0)\n",
    "\n",
    "# 선두에서 5행까지 표시\n",
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.preprocessing.LabelEncoder 사용\n",
    "#### <span style=\"color:red\">fit() : 어떻게 변환할 지 학습</span>\n",
    "#### <span style=\"color:red\">transform(): 문자열를 숫자로 변환</span>\n",
    "#### <span style=\"color:red\">fit_transform() : 학습과 변환을 한번에 처리 (fit + transform)</span>\n",
    "#### inverse_transform() : 숫자를 문자열로 변환\n",
    "#### classes_ : 인코딩한 클래스 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "items = ['TV','TV','냉장고','컴퓨터','냉장고','컴퓨터', '에어콘']\n",
    "le = LabelEncoder()\n",
    "le.fit(items) \n",
    "label = le.transform(items)\n",
    "\n",
    "print(label, type(label))\n",
    "print(le.classes_)\n",
    "print(le.inverse_transform(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass','fnlwgt','education', 'education-num', 'marital-status', 'occupation','relationship', 'race', 'gender','capital-gain','capital-loss', 'hours-per-week','native-country', 'income']\n",
    "import pandas as pd\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "df = pd.read_csv(url, header=None, names=cols, na_values=' ?')\n",
    "print(df.shape)   # (32561, 15)\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding_columns 레이블 인코딩 처리\n",
    "#### -범주형: 'workclass','education', 'education-num', 'marital-status', 'occupation','relationship', 'race', 'gender', 'hours-per-week','native-country', 'income'\n",
    "#### -연속형: 'age', fnlwgt', 'capital-gain', 'capital-loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_columns = ['workclass','education','marital-status', 'occupation','relationship','race','gender','native-country', 'income']\n",
    "not_encoding_columns = ['age','fnlwgt', 'education-num','capital-gain','capital-loss','hours-per-week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_classes = {} \n",
    "def encoding_label_func(x):  #x: 범주형 타입의 컬럼(Series)\n",
    "    le = LabelEncoder()\n",
    "    label = le.fit_transform(x)\n",
    "\n",
    "    enc_classes[x.name] = le.classes_   #x.name: 컬럼명\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = df[encoding_columns].apply(encoding_label_func)\n",
    "d2 = df[not_encoding_columns]\n",
    "data = d1.join(d2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **더미화 - 원핫 인코딩(One-Hot encoding)**\n",
    "#### N개의 클래스를 N 차원의 One-Hot 벡터로 표현되도록 변환\n",
    "#### 고유값들을 피처로 만들고 정답에 해당하는 열은 1로 나머진 0으로 표시\n",
    "#### 변환해야 하는 값의 종류가 여러 개일 때\n",
    "#### 숫자의 차이가 모델에 영향을 미치는 선형 계열 모델(로지스틱회귀, SVM, 신경망)에서 범주형 데이터 변환시 라벨 인코딩 보다 원핫 인코딩을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### [판다스]\n",
    "#### <span style=\"color:red\">pandas.get_dummies(DataFrame [, columns=[변환할 컬럼명]])</span> 함수 이용\n",
    "#### DataFrame에서 범주형(문자열) 변수만 변환\n",
    "----\n",
    "### [사이킷런]\n",
    "#### <span style=\"color:red\">sklearn.preprocessing.OneHotEncoder</span> 이용\n",
    "#### fit(): 어떻게 변환할 지 학습\n",
    "#### transform(): 문자열를 숫자로 변환\n",
    "#### fit_transform(): 학습과 변환을 한번에 처리\n",
    "#### get_feature_names() : 원핫인코딩으로 변환된 컬럼의 이름을 반환\n",
    "#### DataFrame을 넣을 경우 모든 변수들을 변환하므로 범주형 컬럼만 처리하도록 해야 함\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/onehot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **pandas의 get_dummies 기능을 활용한 인코딩**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'item' : ['TV', '냉장고', '전자레인지', '컴퓨터', 'TV', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df, prefix=\"my\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = pd.DataFrame({'name':['apple', 'banana', 'cherry', 'durian', np.nan],\n",
    "                      'color':['red', 'yellow', 'red', 'green', np.nan]})\n",
    "fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(fruit, columns = ['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(fruit['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(fruit['name'], dummy_na = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job을 더미 변수로 변경\n",
    "bank_df_job = pd.get_dummies(bank_df['job'])\n",
    "\n",
    "# 선두에서 5행까지 표시\n",
    "bank_df_job.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marital을 더미 변수로 변경\n",
    "bank_df_marital = pd.get_dummies(bank_df['marital'])\n",
    "bank_df_education = pd.get_dummies(bank_df['education'])\n",
    "bank_df_contact = pd.get_dummies(bank_df['contact'])\n",
    "bank_df_month = pd.get_dummies(bank_df['month'])\n",
    "\n",
    "# 선두에서 5행까지 표시\n",
    "display(bank_df_marital.head())\n",
    "display(bank_df_education.head())\n",
    "display(bank_df_contact.head())\n",
    "display(bank_df_month.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래의 데이터 세트에서 수치항목을 추출\n",
    "tmp1 = bank_df[['age', 'default', 'balance', 'housing', 'loan',\n",
    "                'day', 'duration', 'campaign', 'pdays', 'previous', 'y']]\n",
    "\n",
    "# 선두에서 5행까지 표시\n",
    "tmp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5b8002167af4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 수평결합\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtmp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbank_df_marital\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtmp3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbank_df_education\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtmp4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbank_df_contact\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbank_df_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbank_df_month\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# 수평결합\n",
    "tmp2 = pd.concat([tmp1, bank_df_marital], axis=1)\n",
    "tmp3 = pd.concat([tmp2, bank_df_education], axis=1)\n",
    "tmp4 = pd.concat([tmp3, bank_df_contact], axis=1)\n",
    "bank_df_new = pd.concat([tmp4, bank_df_month], axis=1)\n",
    "\n",
    "print(bank_df_new)\n",
    "# 선두에서 5행까지 표시\n",
    "bank_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "bank_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리한 결과를 CSV파일로 출력\n",
    "bank_df_new.to_csv('output/bank-prep.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷런에서 지원하는 원핫인코딩 구현\n",
    "---\n",
    "## LabelEncoder : 문자형태의 데이터로 구성된 피쳐를 수치화 함\n",
    "\n",
    "## OneHotEncoder : 숫자로 표현된 범주형 데이터를 인코딩 필요\n",
    "###                희소행렬(Sparse Matrix)로 만들어지므로 array로 만들려면 .toarray() 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items=['TV', '냉장고', '전자레인지', '컴퓨터', 'TV', '선풍기', '선풍기', '믹서', '믹서']\n",
    "# 먼저 숫자값으로 변환을 위해 LabelEncoder로 변환\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "# 2차원 데이터로 변환합니다. \n",
    "labels = labels.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [0]\n",
      " [3]\n",
      " [3]\n",
      " [2]\n",
      " [2]]\n",
      "['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(encoder.classes_)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "희소행렬로 만들지 않은 원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(9, 6)\n"
     ]
    }
   ],
   "source": [
    "# 원-핫 인코딩을 적용\n",
    "oh_encoder = OneHotEncoder(sparse=False)\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('희소행렬로 만들지 않은 원-핫 인코딩 데이터')\n",
    "print(oh_labels)\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "희소행렬로 만든 원-핫 인코딩 데이터\n",
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (6, 3)\t1.0\n",
      "  (7, 2)\t1.0\n",
      "  (8, 2)\t1.0\n",
      "2차원 구조로 변환한 원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(9, 6)\n"
     ]
    }
   ],
   "source": [
    "# 원-핫 인코딩을 적용\n",
    "oh_encoder = OneHotEncoder(sparse=True)\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('희소행렬로 만든 원-핫 인코딩 데이터')\n",
    "print(oh_labels)\n",
    "print('2차원 구조로 변환한 원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_0', 'x0_1', 'x0_2', 'x0_3', 'x0_4', 'x0_5'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_encoder.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelBinarizer 클래스를 사용해서 (텍스트 범주에서 숫자 범주로 바꾸고, 숫자 범주에서 원-핫 벡터로 바꾸는) 두개의 변환을 한번에 적용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "jobs_encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "items=['TV', '냉장고', '전자레인지', '컴퓨터', 'TV', '선풍기', '선풍기', '믹서', '믹서']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_encoder.fit(items)\n",
    "transformed = jobs_encoder.transform(items)\n",
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TV', '냉장고', '믹서', '선풍기', '전자레인지', '컴퓨터'], dtype='<U5')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>냉장고</th>\n",
       "      <th>믹서</th>\n",
       "      <th>선풍기</th>\n",
       "      <th>전자레인지</th>\n",
       "      <th>컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TV  냉장고  믹서  선풍기  전자레인지  컴퓨터\n",
       "0   1    0   0    0      0    0\n",
       "1   0    1   0    0      0    0\n",
       "2   0    0   0    0      1    0\n",
       "3   0    0   0    0      0    1\n",
       "4   1    0   0    0      0    0\n",
       "5   0    0   0    1      0    0\n",
       "6   0    0   0    1      0    0\n",
       "7   0    0   1    0      0    0\n",
       "8   0    0   1    0      0    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_df = pd.DataFrame(transformed, columns=jobs_encoder.classes_)\n",
    "ohe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## **EDA 작업이후 데이터 전처리에서 필요한 작업 - 수치형 데이터 전처리**\n",
    "### 각 열(변수, 피처, 속성)이 가지는 값들의 숫자 범위(Scale)가 다를 경우 이 값의 범위를 일정한 범위로 맞추는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalization(정규화) / Standardization(표준화)**\n",
    "\n",
    "### 데이터 분석을 수행하면서 많이 겪는 문제중 하나가 <span style=\"color:red\">데이터 단위의 불일치</span>임\n",
    "### 칼럼간에 데이터의 단위가 다르면 칼럼마다 스케일이 크게 차이가 나게 되고 분석 결과에 영향을 주게 된다.\n",
    "### 이를 해결하는 방법으로 <span style=\"color:blue\">Normalization(정규화)과 Standardization(표준화)</span>가 있음 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **[ 정규화(normalization)]**\n",
    "### 데이터의 상대적 크기에 대한 영향을 줄이기 위해 데이터범위를 0~1로 변환 - MinMax스케일러라고도 함\n",
    "### 2개 이상의 대상 컬럼(변수, 피쳐, 속성)의 단위가 다를 때 대상 데이터를 같은 기준으로 볼 수 있게 함\n",
    "### 데이터가 평균으로부터 얼마나 떨어져있는지 나타내는 값으로, 특정 범위를 벗어난 데이터는 outlier로 간주, 제거 \n",
    "## 식 : <span style=\"color:red\">(측정값 - 최소값) / (최대값 - 최소값)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **[표준화(Standardization)] - Z-score 표준화라고도 함** \n",
    "### 피쳐의 값들이 평균이 0이고 표준편차가 1인 범위(표준정규분포)에 있도록 변환\n",
    "### 데이터가 평균으로부터 얼마나 떨어져있는지 나타내는 값으로, 특정 범위를 벗어난 데이터는 outlier로 간주, 제거 \n",
    "### 특히 SVM이나 선형회귀, 로지스틱 회귀 알고리즘(선형모델)은 데이터셋이 표준정규분포를 따를때 성능이 좋은 모델이기 때문에 \n",
    "### 표준화를 하면 대부분의 경우 성능이 향상\n",
    "### 데이터를 0을 중심으로 양쪽으로 데이터를 분포시키는 방법\n",
    "### 표준화를 하면 각 데이터들이 평균을 기준으로 얼마나 떨여져 있는지를 나타내는 값으로 변환됨\n",
    "## 식(Z-score 표준화) : <span style=\"color:red\">(측정값 - 평균) / 표준편차</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "![](data/test.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.preprocessing의 MinMaxScaler 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "a = [[10], [9], [8], [6], [2]]\n",
    "print(a)\n",
    "print(type(a))\n",
    "print('-------- MinMaxScaling ---------')\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "a = scaler.fit_transform(a)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.preprocessing의 StandardScaler 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "a = [[10], [9], [8], [6], [2]]\n",
    "print(a)\n",
    "scaler = StandardScaler()\n",
    "print('-------- StandardScaling ---------')\n",
    "a = scaler.fit_transform(a)\n",
    "print(a)\n",
    "print('--------------------------------')\n",
    "print('평균 : ', a.mean())\n",
    "print('표준편차 : ', a.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트리계열을 제외한 대부분의 머신러닝 알고리즘들이 피처의 스케일에 영향을 받음\n",
    "#### 선형모델, SVM 모델, 신경망 모델 등\n",
    "\n",
    "#### 특히 SVM이나 선형회귀, 로지스틱 회귀 알고리즘(선형모델)은 데이터셋이 표준정규분포를 따를때 성능이 좋은 모델이기 \n",
    "#### 때문에 표준화를 하면 대부분의 경우 성능이 향상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 표준화를 통해 outlier를 제거한 다음 데이터 정규화를 하여 상대적크기에 대한 영향력을 줄인 다음 분석을 시작한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">EDA와 데이터 전처리 리뷰 샘플</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타이타닉 데이터셋으로 진행한 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "캐글의 타이타닉 데이터셋 페이지 :  https://www.kaggle.com/c/titanic   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "test_PassengerId = test_df[\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 소개\n",
    "* PassengerId: unique id number to each passenger\n",
    "* Survived: passenger survive(1) or died(0)\n",
    "* Pclass: passenger class\n",
    "* Name: name\n",
    "* Sex: gender of passenger\n",
    "* Age: age of passenger\n",
    "* SibSp: number of siblings/spouses\n",
    "* Parch: number of parents/children\n",
    "* Ticket: ticket number\n",
    "* Fare: amount of money spent on ticket\n",
    "* Cabin: cabin category\n",
    "* Embarked: port where passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범주형 변수들 값 갯수 시각화 - 막대그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(variable):\n",
    "    var = train_df[variable]\n",
    "    varValue = var.value_counts()\n",
    "    \n",
    "    # visualize\n",
    "    plt.figure(figsize = (9,3))\n",
    "    plt.bar(varValue.index, varValue)\n",
    "    plt.xticks(varValue.index, varValue.index.values)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(variable)\n",
    "    plt.show()\n",
    "    print(\"{}: \\n {}\".format(variable,varValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\", \"Parch\"]\n",
    "for c in category1:\n",
    "    bar_plot(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category2 = [\"Cabin\", \"Name\", \"Ticket\"]\n",
    "for c in category2:\n",
    "    print(\"{} \\n\".format(train_df[c].value_counts()))\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치형 변수들 값 분포 시각화 - 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(variable):\n",
    "    plt.figure(figsize = (9,3))\n",
    "    plt.hist(train_df[variable], bins = 50)\n",
    "    plt.xlabel(variable)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"{} distribution with hist\".format(variable))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericVar = [\"Fare\", \"Age\",\"PassengerId\"]\n",
    "for n in numericVar:\n",
    "    plot_hist(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기초 데이터 분석\n",
    "\n",
    "* Pclass - 선실 등급에 따른 생존자 비율\n",
    "* Sex - 성별에 따른 생존자 비율\n",
    "* SibSp - 함께 탑승한 형제 또는 자매들의 명수에 따른 생존자 비율\n",
    "* Parch - 부모와 자식이 함께 존재했는지에 따른 생존자 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선실 등급에 따른 생존자 비율\n",
    "train_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성별에 따른 생존자 비율\n",
    "train_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함께 탑승한 형제 또는 자매들의 명수에 따른 생존자 비율\n",
    "train_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모와 자식이 함께 존재했는지에 따른 생존자 비율\n",
    "train_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이상치 채크와 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df,features):\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for c in features:\n",
    "        # 1st quartile\n",
    "        Q1 = np.percentile(df[c],25)\n",
    "        # 3rd quartile\n",
    "        Q3 = np.percentile(df[c],75)\n",
    "        # IQR\n",
    "        IQR = Q3 - Q1\n",
    "        # Outlier step\n",
    "        outlier_step = IQR * 1.5\n",
    "        # detect outlier and their indeces\n",
    "        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n",
    "        # store indeces\n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "    \n",
    "    outlier_indices = Counter(outlier_indices)\n",
    "    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n",
    "    \n",
    "    return multiple_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[27:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "train_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[27:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치 채크와 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_len = len(train_df)\n",
    "train_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns[train_df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"Embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.boxplot(column=\"Fare\",by = \"Embarked\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\n",
    "train_df[train_df[\"Embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화를 통한 변수들간의 관계 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\n",
    "sns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\")\n",
    "g.set_ylabels(\"Survived Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"Parch\", y = \"Survived\", kind = \"bar\", data = train_df)\n",
    "g.set_ylabels(\"Survived Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\")\n",
    "g.set_ylabels(\"Survived Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_df, col = \"Survived\")\n",
    "g.map(sns.histplot, \"Age\", bins = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\")\n",
    "g.map(plt.hist, \"Age\", bins = 25)\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_df, row = \"Embarked\")\n",
    "g.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"Age\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\",data = train_df, kind = \"box\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\n",
    "for i in index_nan_age:\n",
    "    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n",
    "    age_med = train_df[\"Age\"].median()\n",
    "    if not np.isnan(age_pred):\n",
    "        train_df[\"Age\"].iloc[i] = age_pred\n",
    "    else:\n",
    "        train_df[\"Age\"].iloc[i] = age_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"Age\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피쳐 엔지니어링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name -- Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Name\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = train_df[\"Name\"]\n",
    "train_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Title\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Title\", data = train_df)\n",
    "plt.xticks(rotation = 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\n",
    "train_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\n",
    "train_df[\"Title\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Title\", data = train_df)\n",
    "plt.xticks(rotation = 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\n",
    "g.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\n",
    "g.set_ylabels(\"Survival Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df,columns=[\"Title\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\n",
    "g.set_ylabels(\"Survival\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"family_size\", data = train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\n",
    "g.set_ylabels(\"Survival\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Embarked\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"Embarked\", data = train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Ticket\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"A/5. 2151\"\n",
    "a.replace(\".\",\"\").replace(\"/\",\"\").strip().split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tickets = []\n",
    "for i in list(train_df.Ticket):\n",
    "    if not i.isdigit():\n",
    "        tickets.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(\" \")[0])\n",
    "    else:\n",
    "        tickets.append(\"x\")\n",
    "train_df[\"Ticket\"] = tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Ticket\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\")\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"Pclass\", data = train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\n",
    "train_df = pd.get_dummies(train_df, columns= [\"Pclass\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\n",
    "train_df = pd.get_dummies(train_df, columns=[\"Sex\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Passenger ID and Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_df[train_df_len:]\n",
    "test.drop(labels = [\"Survived\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = train_df[:train_df_len]\n",
    "X_train = train.drop(labels = \"Survived\", axis = 1)\n",
    "y_train = train[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\n",
    "print(\"X_train\",len(X_train))\n",
    "print(\"X_test\",len(X_test))\n",
    "print(\"y_train\",len(y_train))\n",
    "print(\"y_test\",len(y_test))\n",
    "print(\"test\",len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "acc_log_train = round(logreg.score(X_train, y_train)*100,2) \n",
    "acc_log_test = round(logreg.score(X_test,y_test)*100,2)\n",
    "print(\"Training Accuracy: % {}\".format(acc_log_train))\n",
    "print(\"Testing Accuracy: % {}\".format(acc_log_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/kanncaa1/dataiteam-titanic-eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
